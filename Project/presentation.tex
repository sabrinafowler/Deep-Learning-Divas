\documentclass{beamer}

\usetheme[hideothersubsections]{UNLTheme}

% Suppress overfull hbox warnings from theme logo sizing
\hfuzz=52pt


\title{Multi-Modal\texorpdfstring{\\}{, }Data Retrieval}
\author{Deep Learning Divas}
\date{December 10, 2025}

\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\section{Introduction}
% define the problem
% present a "carrot"
% put in context
% give outline at the end of the introduction

\begin{frame}
    \frametitle{The Problem}
    \begin{itemize}
        \item How do we search for images using text queries?
        \begin{itemize}
            \item Or find relevant captions for a given image?
        \end{itemize}
        \item Challenge: Images and text live in different spaces
        \begin{itemize}
            \item Images: pixel intensities, visual features
            \item Text: words, semantic meanings
        \end{itemize}
        \item Need: A shared representation to bridge modalities
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Why Does This Matter?}
    \begin{itemize}
        \item Real-world applications:
        \begin{itemize}
            \item Image search engines
            \item Content-based retrieval systems
            \item Accessibility tools for visually impaired users
        \end{itemize}
        \item Traditional approach: Treat modalities separately
        \begin{itemize}
            \item Limited cross-modal understanding
        \end{itemize}
        \item Our opportunity: Modern deep learning enables shared representations
        \begin{itemize}
            \item More accurate retrieval
            \item Better generalization across domains
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Our Solution: Modernizing Correspondence Autoencoders}
    \begin{itemize}
        \item Original Corr-AE (Feng et al., 2014)
        \begin{itemize}
            \item Used Restricted Boltzmann Machines for feature extraction
            \item Shared latent space for image and text
        \end{itemize}
        \item Our modernized approach:
        \begin{itemize}
            \item Replace RBMs with pretrained models:
            \begin{itemize}
                \item ResNet-50 for image features
                \item BERT for text embeddings
            \end{itemize}
            \item Compare multiple autoencoder architectures
            \item Evaluate different alignment loss functions
        \end{itemize}
        \item Dataset: Flickr8k (8,000 images, 5 captions each)
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Outline}
    \begin{enumerate}
        \item Background \& Related Work
        \item Methodology
        \begin{itemize}
            \item Feature extraction
            \item Autoencoder architectures
            \item Loss functions
        \end{itemize}
        \item Experimental Results
        \begin{itemize}
            \item Performance metrics
            \item Architecture comparison
        \end{itemize}
        \item Conclusions \& Future Work
    \end{enumerate}
\end{frame}

% Body: high level summary of key results
% Technicalities: more depth into a key result
% Conclusion: review key results, wrap up, give future work
    
\end{document}